{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Test all the different functionalities that were implemented\n",
    "\n",
    "### already tested (state 29.08.2020)\n",
    "- linear_regression class\n",
    "- clustering (still some bugs in function 'get_dendrogram_data')\n",
    "- dimension reduction (LDA + PCA)\n",
    "- Gaussian Mixture Models with Expectation Maximization Algorithm\n",
    "- Gaussian Processes\n",
    "- Reinforcement Learning (Action-Value-iteration and Q-learning)\n",
    "- Hidden Markov Models (Markov Processes, forward- + backward-progresses, viterbi-algorithm and model estimation)\n",
    "- Deep Learnign using Neural Networks\n",
    "- Genetic Algorithm for dataset manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import numpy as np\n",
    "# import library.classic_ml\n",
    "# reload(library.classic_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import linear_regression\n",
    "# lr = linear_regression()\n",
    "\n",
    "# x = [-3, -1, 0, 2, 4]\n",
    "# y = [-4, 1, 1, 2, 6]\n",
    "# x_test = x\n",
    "\n",
    "# x2 = [[1,2],[2,1]]\n",
    "# y2 = [[2,2],[3,4]]\n",
    "# x2_test = [[2,1]]\n",
    "\n",
    "# lr.train(x,y,mode=\"l\")\n",
    "# lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import clustering\n",
    "# c = clustering()\n",
    "\n",
    "# data = np.array([[2,2.5],[7,0.5],[12,1],[4,-0.5],[10,2],[3,2],[7,0],[9,1.5],[4,2.5],[10,1]])\n",
    "# x_test = np.array([[1,5]])\n",
    "# c.train(data, mode=\"nubs\")\n",
    "# c.predict(x_test)\n",
    "# dd_data = c.get_dendrogram_data(c.cluster_centers, c.labels,\"average\")\n",
    "# print(dd_data)\n",
    "# c.make_dendrogram(dd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import dimension_reduction\n",
    "# d = dimension_reduction()\n",
    "\n",
    "# class1 = np.array([[4,1],[2,4],[2,3],[3,6],[4,4]])\n",
    "# class2 = np.array([[9,10],[6,8],[9,5],[8,7],[10,8]])\n",
    "# test = np.array([7,4])\n",
    "# d.pca(np.array(class1),1,1)\n",
    "# d.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import gmm\n",
    "# g = gmm()\n",
    "\n",
    "# xs1 = [1,3,4]\n",
    "# xs = [[0,1],[0.5,1],[4,6],[5,7],[8,7]]\n",
    "# xs_test = [7,4]\n",
    "# xs1_test = [5]\n",
    "# g.train(xs)\n",
    "# l1 = g.predict(xs_test)\n",
    "# g.train(xs1)\n",
    "# l2 = g.predict(xs1_test)\n",
    "# l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import gp\n",
    "# gp = gp()\n",
    "\n",
    "# x = np.array([1,1.2,1.4])\n",
    "# x_3 = np.array([1.4,2])\n",
    "# x_t = np.array([1.6])\n",
    "\n",
    "# y = np.array([1.5,1,0.8])\n",
    "# y_test, cov = gp.train(x,x,y,0.1,0.3,\"rbf\",True)\n",
    "# y_test, cov, y_test.shape, cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from importlib import reload\n",
    "# import library.reinforcement_learning\n",
    "# reload(library.reinforcement_learning)\n",
    "# from library.reinforcement_learning import reinforcement_learning\n",
    "# rl = reinforcement_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([1, 2, 3, 4])\n",
    "# rewards = np.array([1, -1, -1, 10])\n",
    "# gamma = 0.9\n",
    "# actions = np.array([-1,1])\n",
    "# probabilities = np.array([0.8,0.2])\n",
    "# probabilities = np.sort(probabilities)[::-1]\n",
    "# terminal_states = np.array([1, 4])\n",
    "# tolerance = 0.1\n",
    "# rl.action_value_iteration(states, actions, rewards, terminal_states, probabilities, gamma, tolerance, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([[1, 2, 3, 4],[5, \"x\", 7, 8],[9, 10, 11, 12]])\n",
    "# rewards = np.array([[0, 0, 0, 0],[0, 0, 0, -10],[0, 0, 0, 1]])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,0,1])\n",
    "# probabilities = np.array([0.1,0.1,0.8])\n",
    "# probabilities = np.sort(probabilities)[::-1]\n",
    "# terminal_states = np.array([(2,3), (1,3)])\n",
    "\n",
    "# tolerance = 0.1\n",
    "# rl.action_value_iteration(states, actions, rewards, terminal_states, probabilities, gamma, tolerance, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([1, 2, 3, 4])\n",
    "# rewards = np.array([1, -1, -1, 10])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,1])\n",
    "# probabilities = np.array([0.8,0.2])\n",
    "# probabilities = np.sort(probabilities)\n",
    "# terminal_states = np.array([0, 3])\n",
    "# steps = 10\n",
    "\n",
    "# probs = np.random.choice(actions.astype(str),steps,p=probabilities)\n",
    "# directions = np.random.choice([\"R\",\"L\"],steps,p=[1/len(actions) for _ in actions])\n",
    "# sequence = np.array([\"\".join(el) for el in np.vstack((directions, probs)).T])\n",
    "# transition  = {\"R1\": 1, \"R-1\": -1, \"L1\": -1, \"L-1\": 1}\n",
    "# rl.q_learning(states, actions, rewards, terminal_states, sequence, transition, gamma, alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([[1, 2, 3, 4],[5, \"x\", 7, 8],[9, 10, 11, 12]])\n",
    "# rewards = np.array([[0, 0, 0, 0],[0, 0, 0, -10],[0, 0, 0, 1]])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,0,1])\n",
    "# probabilities = np.array([0.1,0.1,0.8])\n",
    "# terminal_states = np.array([(2,3), (1,3)])\n",
    "\n",
    "# steps = 1000\n",
    "\n",
    "# probs = np.random.choice(actions.astype(str),steps,p=probabilities)\n",
    "# directions = np.random.choice([\"R\",\"S\",\"L\"],steps,p=[1/len(actions) for _ in actions])\n",
    "# sequence = np.array([\"\".join(el) for el in np.vstack((directions, probs)).T])\n",
    "# transition  = {\"R1\": 1, \"R0\": 0, \"R-1\": -1, \"S1\": 0, \"S0\": 1, \"S-1\": -1, \"L1\": -1, \"L0\": 0, \"L-1\": 1}\n",
    "# rl.q_learning(states, actions, rewards, terminal_states, sequence, transition, gamma, alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0756\n",
      "0.0028000000000000013\n",
      "0.009629600000000004\n",
      "0.009629600000000002\n",
      "(0.0028224000000000014, ['C', 'C', 'C', 'H'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.55807991, 0.44192009],\n",
       "        [0.49898142, 0.50101858]]),\n",
       " array([[0.23961928, 0.29844534, 0.46193538],\n",
       "        [0.70056364, 0.21268397, 0.08675238]]),\n",
       " {'H': 0.1881698097532607, 'C': 0.8118301902467392})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# A = np.array([\n",
    "#     [0.7, 0.3],\n",
    "#     [0.4, 0.6]\n",
    "# ])\n",
    "# B = np.array([\n",
    "#     [0.1, 0.4, 0.5],\n",
    "#     [0.7, 0.2, 0.1]\n",
    "# ])\n",
    "# pi = {\n",
    "#     \"H\": 0.6,\n",
    "#     \"C\": 0.4\n",
    "# }\n",
    "# states = {\n",
    "#     \"H\": 0,\n",
    "#     \"C\": 1\n",
    "# }\n",
    "# observations = {\n",
    "#     \"small\": 0,\n",
    "#     \"medium\": 1,\n",
    "#     \"large\": 2\n",
    "# }\n",
    "\n",
    "# sequence1 = [\n",
    "#     \"H\", \"H\", \"C\", \"C\"\n",
    "# ]\n",
    "# sequence2 = [\n",
    "#     (\"small\", \"H\"), (\"medium\", \"H\"), (\"small\", \"C\"), (\"large\", \"C\")\n",
    "# ]\n",
    "# sequence = [\n",
    "#     \"small\",\"medium\",\"small\",\"large\"\n",
    "# ]\n",
    "\n",
    "# from importlib import reload\n",
    "# import library.reinforcement_learning\n",
    "# reload(library.reinforcement_learning)\n",
    "# from library.reinforcement_learning import hmm\n",
    "# hmm = hmm(A, B, pi, states, observations)\n",
    "# print(hmm.MP(sequence1))\n",
    "# print(hmm.MP(sequence2))\n",
    "# print(hmm.forward(sequence))\n",
    "# print(hmm.backward(sequence))\n",
    "# print(hmm.viterbi(sequence))\n",
    "# hmm.model_estimation(sequence)\n",
    "# hmm.A, hmm.B, hmm.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import autograd.numpy as np\n",
    "\n",
    "# X = 2*np.pi*np.random.rand(10).reshape(1,-1).astype(float)\n",
    "# y = np.sin(X).astype(float)\n",
    "\n",
    "# from library.deep_learning import NeuralNetwork\n",
    "\n",
    "# nn = NeuralNetwork([X.shape[0], 40, 20, 10, 5, X.shape[0]])\n",
    "# nn.train(X, y, epochs=int(1e5), lr=0.1)\n",
    "# nn.predict(X,y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a025e6465740f4a08ae728a6852cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best generation reaches a minimum cost of 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_x = 1000\n",
    "days = 1\n",
    "hours = 24\n",
    "\n",
    "X = np.array([np.random.randint(0, 2, size=(hours, days)) for _ in range(num_x)])\n",
    "y = np.random.randint(0, 2, size=(hours, days))\n",
    "\n",
    "from library.genetic_algorithm import genetic_algorithm\n",
    "ga = genetic_algorithm()\n",
    "generations = int(1e3)\n",
    "sf = ga.train(X, y, generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
