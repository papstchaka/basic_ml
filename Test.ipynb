{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Test all the different functionalities that were implemented\n",
    "\n",
    "### already tested (state 29.08.2020)\n",
    "- linear_regression class\n",
    "- clustering (still some bugs in function 'get_dendrogram_data')\n",
    "- dimension reduction (LDA + PCA)\n",
    "- Gaussian Mixture Models with Expectation Maximization Algorithm\n",
    "- Gaussian Processes\n",
    "- Reinforcement Learning (Action-Value-iteration and Q-learning)\n",
    "- Hidden Markov Models (Markov Processes, forward- + backward-progresses, viterbi-algorithm and model estimation)\n",
    "- Deep Learnign using Neural Networks\n",
    "- Genetic Algorithm for dataset manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import numpy as np\n",
    "# import library.classic_ml\n",
    "# reload(library.classic_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import linear_regression\n",
    "# lr = linear_regression()\n",
    "\n",
    "# x = [-3, -1, 0, 2, 4]\n",
    "# y = [-4, 1, 1, 2, 6]\n",
    "# x_test = x\n",
    "\n",
    "# x2 = [[1,2],[2,1]]\n",
    "# y2 = [[2,2],[3,4]]\n",
    "# x2_test = [[2,1]]\n",
    "\n",
    "# lr.train(x,y)\n",
    "# y_pred = lr.predict(x_test)\n",
    "# lr.score(x_test, y_pred, \"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import clustering\n",
    "# c = clustering()\n",
    "\n",
    "# data = np.array([[2,2.5],[7,0.5],[12,1],[4,-0.5],[10,2],[3,2],[7,0],[9,1.5],[4,2.5],[10,1]])\n",
    "# x_test = np.array([[1,5]])\n",
    "# y_test = [\"2\"]\n",
    "# c.train(data, mode=\"nubs\")\n",
    "# y_pred = c.predict(x_test)\n",
    "# dd_data = c.get_dendrogram_data(c.cluster_centers, c.labels,\"average\")\n",
    "# print(dd_data)\n",
    "# c.make_dendrogram(dd_data)\n",
    "# c.score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import dimension_reduction\n",
    "# d = dimension_reduction()\n",
    "\n",
    "# class1 = np.array([[4,1],[2,4],[2,3],[3,6],[4,4]])\n",
    "# class2 = np.array([[9,10],[6,8],[9,5],[8,7],[10,8]])\n",
    "\n",
    "# d.fit_transform(np.array([class1,class2]), \"lda\")\n",
    "# d.fit_transform(class1, \"pca\", dim = 1)\n",
    "# d.fit_transform(class1, \"fastica\", n_components = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import gmm\n",
    "# g = gmm()\n",
    "\n",
    "# xs1 = [1,3,4]\n",
    "# xs = [[0,1],[0.5,1],[4,6],[5,7],[8,7]]\n",
    "# xs_test = [7,4]\n",
    "# xs1_test = [5]\n",
    "# g.train(xs)\n",
    "# l1 = g.predict(xs_test)\n",
    "# g.train(xs1)\n",
    "# l2 = g.predict(xs1_test)\n",
    "# l1, l2\n",
    "# g.score([0], [l2], \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from library.classic_ml import gp\n",
    "# gp = gp()\n",
    "\n",
    "# x = np.array([1,1.2,1.4])\n",
    "# x_3 = np.array([1.4,2])\n",
    "# x_t = np.array([1.6])\n",
    "\n",
    "# y = np.array([1.5,1,0.8])\n",
    "# gp.train(x,x,0.1,0.3,\"rbf\")\n",
    "# y_test, cov = gp.predict(y, True)\n",
    "# gp.score(x,y_test,\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from importlib import reload\n",
    "# import library.reinforcement_learning\n",
    "# reload(library.reinforcement_learning)\n",
    "# from library.reinforcement_learning import reinforcement_learning\n",
    "# rl = reinforcement_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([1, 2, 3, 4])\n",
    "# rewards = np.array([1, -1, -1, 10])\n",
    "# gamma = 0.9\n",
    "# actions = np.array([-1,1])\n",
    "# probabilities = np.array([0.8,0.2])\n",
    "# probabilities = np.sort(probabilities)[::-1]\n",
    "# terminal_states = np.array([1, 4])\n",
    "# tolerance = 0.1\n",
    "# rl.action_value_iteration(states, actions, rewards, terminal_states, probabilities, gamma, tolerance, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([[1, 2, 3, 4],[5, \"x\", 7, 8],[9, 10, 11, 12]])\n",
    "# rewards = np.array([[0, 0, 0, 0],[0, 0, 0, -10],[0, 0, 0, 1]])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,0,1])\n",
    "# probabilities = np.array([0.1,0.1,0.8])\n",
    "# probabilities = np.sort(probabilities)[::-1]\n",
    "# terminal_states = np.array([(2,3), (1,3)])\n",
    "\n",
    "# tolerance = 0.1\n",
    "# rl.action_value_iteration(states, actions, rewards, terminal_states, probabilities, gamma, tolerance, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([1, 2, 3, 4])\n",
    "# rewards = np.array([1, -1, -1, 10])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,1])\n",
    "# probabilities = np.array([0.8,0.2])\n",
    "# probabilities = np.sort(probabilities)\n",
    "# terminal_states = np.array([0, 3])\n",
    "# steps = 10\n",
    "\n",
    "# probs = np.random.choice(actions.astype(str),steps,p=probabilities)\n",
    "# directions = np.random.choice([\"R\",\"L\"],steps,p=[1/len(actions) for _ in actions])\n",
    "# sequence = np.array([\"\".join(el) for el in np.vstack((directions, probs)).T])\n",
    "# transition  = {\"R1\": 1, \"R-1\": -1, \"L1\": -1, \"L-1\": 1}\n",
    "# rl.q_learning(states, actions, rewards, terminal_states, sequence, transition, gamma, alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# states = np.array([[1, 2, 3, 4],[5, \"x\", 7, 8],[9, 10, 11, 12]])\n",
    "# rewards = np.array([[0, 0, 0, 0],[0, 0, 0, -10],[0, 0, 0, 1]])\n",
    "# gamma = 0.9\n",
    "# alpha = (1/3)\n",
    "# actions = np.array([-1,0,1])\n",
    "# probabilities = np.array([0.1,0.1,0.8])\n",
    "# terminal_states = np.array([(2,3), (1,3)])\n",
    "\n",
    "# steps = 1000\n",
    "\n",
    "# probs = np.random.choice(actions.astype(str),steps,p=probabilities)\n",
    "# directions = np.random.choice([\"R\",\"S\",\"L\"],steps,p=[1/len(actions) for _ in actions])\n",
    "# sequence = np.array([\"\".join(el) for el in np.vstack((directions, probs)).T])\n",
    "# transition  = {\"R1\": 1, \"R0\": 0, \"R-1\": -1, \"S1\": 0, \"S0\": 1, \"S-1\": -1, \"L1\": -1, \"L0\": 0, \"L-1\": 1}\n",
    "# rl.q_learning(states, actions, rewards, terminal_states, sequence, transition, gamma, alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# A = np.array([\n",
    "#     [0.7, 0.3],\n",
    "#     [0.4, 0.6]\n",
    "# ])\n",
    "# B = np.array([\n",
    "#     [0.1, 0.4, 0.5],\n",
    "#     [0.7, 0.2, 0.1]\n",
    "# ])\n",
    "# pi = {\n",
    "#     \"H\": 0.6,\n",
    "#     \"C\": 0.4\n",
    "# }\n",
    "# states = {\n",
    "#     \"H\": 0,\n",
    "#     \"C\": 1\n",
    "# }\n",
    "# observations = {\n",
    "#     \"small\": 0,\n",
    "#     \"medium\": 1,\n",
    "#     \"large\": 2\n",
    "# }\n",
    "\n",
    "# sequence1 = [\n",
    "#     \"H\", \"H\", \"C\", \"C\"\n",
    "# ]\n",
    "# sequence2 = [\n",
    "#     (\"small\", \"H\"), (\"medium\", \"H\"), (\"small\", \"C\"), (\"large\", \"C\")\n",
    "# ]\n",
    "# sequence = [\n",
    "#     \"small\",\"medium\",\"small\",\"large\"\n",
    "# ]\n",
    "\n",
    "# from importlib import reload\n",
    "# import library.reinforcement_learning\n",
    "# reload(library.reinforcement_learning)\n",
    "# from library.reinforcement_learning import hmm\n",
    "# hmm = hmm(A, B, pi, states, observations)\n",
    "# print(hmm.MP(sequence1))\n",
    "# print(hmm.MP(sequence2))\n",
    "# print(hmm.forward(sequence))\n",
    "# print(hmm.backward(sequence))\n",
    "# print(hmm.viterbi(sequence))\n",
    "# hmm.model_estimation(sequence)\n",
    "# hmm.A, hmm.B, hmm.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "the_x = np.array([\n",
    "    [0,0,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,1,0], [0,0,1,0,0,0,1,0,0], \n",
    "    [0,0,0,1,0,1,0,0,0], [0,0,0,0,1,0,0,0,0], [0,0,0,1,0,1,0,0,0], \n",
    "    [0,0,1,0,0,0,1,0,0], [0,1,0,0,0,0,0,1,0], [0,0,0,0,0,0,0,0,0]\n",
    "])\n",
    "the_o = np.array([\n",
    "    [0,0,0,0,0,0,0,0,0], [0,0,0,1,1,1,0,0,0], [0,0,1,0,0,0,1,0,0], \n",
    "    [0,1,0,0,0,0,0,1,0], [0,1,0,0,0,0,0,1,0], [0,1,0,0,0,0,0,1,0], \n",
    "    [0,0,1,0,0,0,1,0,0], [0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,0,0]\n",
    "])\n",
    "\n",
    "def shuffle(data:np.array) -> np.array:\n",
    "    new_data = data.copy()\n",
    "    num_ones = new_data[new_data == 1]\n",
    "    zeros = np.zeros(int(num_ones.__len__() * np.random.randint(0,2) / 10))\n",
    "    ones = np.ones(num_ones.__len__() - zeros.__len__())\n",
    "    new_ones = np.append(ones,zeros)\n",
    "    np.random.shuffle(new_ones)\n",
    "    new_data[new_data == 1] = new_ones\n",
    "    return new_data\n",
    "\n",
    "sample_size = 10\n",
    "batch_size = 4\n",
    "\n",
    "dim1, dim2 = the_x.shape\n",
    "Xx = np.array([shuffle(the_x) for _ in range(sample_size)])\n",
    "Ox = np.array([shuffle(the_o) for _ in range(sample_size)])\n",
    "Xy = np.array([np.array([1]) for _ in range(sample_size)])\n",
    "Oy = np.array([np.array([0]) for _ in range(sample_size)])\n",
    "X = np.append(Xx, Ox).reshape(-1, dim1, dim2, 1)\n",
    "y = np.append(Xy, Oy).reshape(-1, 1)\n",
    "X_test = shuffle(the_x).reshape(1, dim1, dim2, 1)\n",
    "y_test = np.array([1]).reshape(1,-1)\n",
    "\n",
    "from library.deep_learning import Dense, ReLU, Convolution, Pooling, Dropout, Flatten, ClassifierNetwork, EarlyStopping\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "network = []\n",
    "network.append(Convolution(4, 2, activation_function = \"relu\"))\n",
    "network.append(Pooling())\n",
    "network.append(ReLU())\n",
    "network.append(Flatten())\n",
    "network.append(Dense(2))\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(\"metrics\"))\n",
    "\n",
    "nn = ClassifierNetwork(network)\n",
    "nn.train(X, y, batch_size = batch_size, epochs = int(1*1e5), loss_func=\"categorical-cross-entropy\", callbacks = callbacks, verbose = 0)\n",
    "nn.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# num_x = 1000\n",
    "# days = 1\n",
    "# hours = 24\n",
    "\n",
    "# X = np.array([np.random.randint(0, 2, size=(hours, days)) for _ in range(num_x)])\n",
    "# y = np.random.randint(0, 2, size=(hours, days))\n",
    "\n",
    "# from library.genetic_algorithm import genetic_algorithm\n",
    "# ga = genetic_algorithm()\n",
    "# generations = int(1e3)\n",
    "# sf = ga.train(X, y, generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
